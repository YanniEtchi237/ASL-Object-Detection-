# Real-time American Sign Language (ASL) Detection with YOLO

## Overview

This project aims to develop a real-time American Sign Language (ASL) detection system using the YOLO (You Only Look Once) object detection model. The system is capable of recognizing ASL gestures and signs from live video input, making it useful for various applications, including communication aids for individuals with hearing impairments.

## Features

- Real-time detection of ASL gestures and signs from live video input.
- User-friendly interface for interacting with the ASL detection system.
- High accuracy and speed in recognizing ASL signs across different lighting conditions and hand orientations.

## Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/yourusername/asl-yolo-detection.git
    cd asl-yolo-detection
    ```

2. Install dependencies:

    ```bash
    pip install -r requirements.txt
    ```

## Usage

1. Run the ASL detection system:

    ```bash
    python main.py
    ```

2. Follow the on-screen instructions to interact with the system:
   - Use the camera to capture live video input.
   - View the real-time detection of ASL signs overlaid on the video feed.
   - Receive feedback on the recognized ASL signs.


## Credits

- YOLOv3: [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)
- ASL Dataset: [ASL Alphabet Dataset](https://www.kaggle.com/grassknoted/asl-alphabet)
- OpenCV: [OpenCV: Open Source Computer Vision Library](https://opencv.org/)

